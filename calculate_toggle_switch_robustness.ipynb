{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Dataset Generator\n",
    "\n",
    "This file generates robustness datasets for the article titled \"Model guided design of enhanced bi-stable controllers to  effectively switch cellular states\" (Raj K., Wong W. T. Z., Zhang B., & Mahadevan R.) (2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has a number of dependencies \n",
    "- PyDSTool (For bifurcation analysis)\n",
    "- plotly (for plotting)\n",
    "- joblib (for parallel computation of results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyDSTool import * \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"none\"\n",
    "import sys\n",
    "if 'ipykernel' in sys.modules:\n",
    "    from plotly.offline import init_notebook_mode\n",
    "    from plotly.offline import iplot as plot\n",
    "    from IPython.display import HTML\n",
    "    HTML(\"\"\"\n",
    "         <script>\n",
    "          var waitForPlotly = setInterval( function() {\n",
    "          if( typeof(window.Plotly) !== \"undefined\" ){\n",
    "          MathJax.Hub.Config({ SVG: { font: \"STIX-Web\" }, displayAlign: \"center\" });\n",
    "          MathJax.Hub.Queue([\"setRenderer\", MathJax.Hub, \"SVG\"]);\n",
    "          clearInterval(waitForPlotly);}}, 250 );\n",
    "        </script>\n",
    "        \"\"\"\n",
    "    )\n",
    "    init_notebook_mode(connected=True)\n",
    "import numpy as np\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline as interpolate\n",
    "from PyDSTool.PyCont.Continuation import PyDSTool_ExistError\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import time\n",
    "import warnings\n",
    "import plotly\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions that will calculate continuity curves.\n",
    "- First generate a continuity class object on PyDS tool: This is where the model is defined\n",
    "- Then compute an equilibrium point for the model and obtain one set of limit points through one parameter continuity.\n",
    "- Then, using that limit point as a starting point, perform 2 parameter continuity on the protein production rates.\n",
    "- For both 1 parameter continuity and 2 parameter continuity, the code performs redundant calculations until a valid limit point is obtained. This is needed because the limit point calculation on PyDSTool is unstable in many conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_class_gen(params_dict):\n",
    "\n",
    "    kp_1_par = Par(params_dict['kdeg_1']*10*params_dict['kdiss_2'], 'kp_1')\n",
    "    kp_2_par = Par(params_dict['kdeg_2']*10*params_dict['kdiss_1'], 'kp_2')\n",
    "    kdiss_1_par = Par(params_dict['kdiss_1'], 'k_diss_1')\n",
    "    kdiss_2_par = Par(params_dict['kdiss_2'], 'k_diss_2')\n",
    "    kdeg_1_par = Par(params_dict['kdeg_1'], 'k_deg_1')\n",
    "    kdeg_2_par = Par(params_dict['kdeg_2'], 'k_deg_2')\n",
    "    n_1_par = Par(params_dict['n_1'], 'n_1')\n",
    "    n_2_par = Par(params_dict['n_2'], 'n_2')\n",
    "\n",
    "    lac_i = Var('lac_i')\n",
    "    tet_r = Var('tet_r')\n",
    "    dlaci_dt = kp_1_par/(1+(tet_r/kdiss_1_par)**n_1_par) - kdeg_1_par*lac_i\n",
    "    dtetr_dt = kp_2_par/(1+(lac_i/kdiss_2_par)**n_2_par) - kdeg_2_par*tet_r\n",
    "\n",
    "    DSargs = args(name='Simple Toggle Equilibrium Model')\n",
    "    DSargs.pars = [kp_1_par, kp_2_par, kdiss_1_par, kdiss_2_par, kdeg_1_par, kdeg_2_par, n_1_par, n_2_par]\n",
    "    DSargs.varspecs = args(lac_i=dlaci_dt,\n",
    "                           tet_r=dtetr_dt)\n",
    "\n",
    "    DSargs.fnspecs = {'Jacobian': (['t','lac_i','tet_r'],\n",
    "                                    \"\"\"[[-k_deg_1, -(kp_1*n_1/k_diss_1**n_1)*(tet_r**(n_1-1)/(1+(tet_r/k_diss_1)**n_1)**2) ],\n",
    "                                        [ -(kp_2*n_2/k_diss_2**n_2)*(lac_i**(n_2-1)/(1+(lac_i/k_diss_2)**n_2)**2),  -k_deg_2 ]]\"\"\")}\n",
    "    DSargs.ics = args(lac_i=10*params_dict['kdiss_2']/params_dict['kdiss_1'], tet_r=params_dict['kdiss_2']/params_dict['kdiss_1']/100)\n",
    "\n",
    "    DSargs.xdomain = {'lac_i': [0, 100000000],\n",
    "                      'tet_r': [0, 100000000]}\n",
    "    DSargs.tdomain = [0, 1000000000]\n",
    "    DSargs.pdomain = {'kp_1': [0, 100000000], 'kp_2': [0, 100000000],\n",
    "                     'k_diss_1': [0.00, 1000000000],\n",
    "                     'k_diss_2': [0.000, 100000000],\n",
    "                     'k_deg_1': [0.0, 100000000],\n",
    "                     'k_deg_2': [0.0, 1000000000],\n",
    "                     'n_1':[1, 8],\n",
    "                    'n_2':[1, 8]}\n",
    "\n",
    "    ode_sys = Generator.Vode_ODEsystem(DSargs)\n",
    "    con_ode_sys = ContClass(ode_sys)\n",
    "    return con_ode_sys\n",
    "\n",
    "def get_limit_points(con_ode_sys):\n",
    "    try:\n",
    "        LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "        LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        LP3 = con_ode_sys['EQ1'].getSpecialPoint('LP3')\n",
    "        LP4 = con_ode_sys['EQ1'].getSpecialPoint('LP4')\n",
    "    except:\n",
    "        return []\n",
    "    LP_list = [LP for LP in [LP1, LP2, LP3, LP4] if LP and LP[con_ode_sys['EQ1'].freepars[0]]>0]\n",
    "    unique_lp_vals = list(set([np.round(LP[con_ode_sys['EQ1'].freepars[0]], 5) for LP in LP_list]))\n",
    "    final_lp_list = []\n",
    "    for LP in LP_list:\n",
    "        if np.round(LP[con_ode_sys['EQ1'].freepars[0]], 5) in unique_lp_vals:\n",
    "            unique_lp_vals.remove(np.round(LP[con_ode_sys['EQ1'].freepars[0]], 5))\n",
    "            final_lp_list.append(LP.labels['LP']['name'])\n",
    "    LP_list = final_lp_list\n",
    "\n",
    "    LP_list = sorted(LP_list, key=lambda x: con_ode_sys['EQ1'].getSpecialPoint(x)[con_ode_sys['EQ1'].freepars[0]])\n",
    "    return LP_list\n",
    "\n",
    "def generate_equilibrium_curve(params_dict, threshold):\n",
    "    con_ode_sys = con_class_gen(params_dict)\n",
    "    PCargs = args(name='EQ1',type='EP-C', force=True)\n",
    "    if con_ode_sys.model.pars['kp_1'] > params_dict['kp_2']: #Determine which kdeg is higher and change corresponding kp because that gives finer variations in limit point determination\n",
    "        PCargs.freepars = ['kp_1']\n",
    "    else:\n",
    "        PCargs.freepars = ['kp_2']\n",
    "\n",
    "\n",
    "    PCargs.StepSize = 1e-3\n",
    "    PCargs.MaxNumPoints = 500\n",
    "    PCargs.MaxStepSize = max(params_dict['kdeg_1'], params_dict['kdeg_2'])/10*min(params_dict['kdiss_1'], params_dict['kdiss_2'])*10000\n",
    "    PCargs.MinStepSize = 1e-7\n",
    "    PCargs.LocBifPoints = ['LP']\n",
    "    PCargs.StopAtPoints = ['LP']\n",
    "    con_ode_sys.newCurve(PCargs)\n",
    "\n",
    "    try:\n",
    "        con_ode_sys['EQ1'].backward()\n",
    "        con_ode_sys['EQ1'].backward()\n",
    "        LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "        LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "    except:\n",
    "        print('fail')\n",
    "        LP1 = None\n",
    "        LP2 = None\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('enter')\n",
    "        freepars = {'kp_1': 'kp_2', 'kp_2': 'kp_1'}\n",
    "        PCargs.freepars = [freepars[PCargs.freepars[0]]]\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "            LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        except:\n",
    "            print('fail')\n",
    "            LP1 = None\n",
    "            LP2 = None\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('enter2')\n",
    "        PCargs.MaxStepSize = PCargs.MaxStepSize/10\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "            LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        except:\n",
    "            print('fail')\n",
    "            LP1 = None\n",
    "            LP2 = None\n",
    "\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('OH NO')\n",
    "        PCargs.initpoint = {'lac_i': 100,\n",
    "                            'tet_r': 0.0001,\n",
    "                            PCargs.freepars[0]:0.00001}\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "            LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        except:\n",
    "            print('fail')\n",
    "            LP1 = None\n",
    "            LP2 = None\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('Still no')\n",
    "        PCargs.MaxStepSize = 1\n",
    "        freepars = {'kp_1': 'kp_2', 'kp_2': 'kp_1'}\n",
    "        PCargs.freepars = [freepars[PCargs.freepars[0]]]\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        PCargs.initpoint = {'lac_i': 1,\n",
    "                    'tet_r': .001,\n",
    "                    PCargs.freepars[0]:0.0001}\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "            LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        except:\n",
    "            print('fail')\n",
    "            LP1 = None\n",
    "            LP2 = None\n",
    "            \n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('Still no')\n",
    "        PCargs.MaxStepSize = 10\n",
    "        freepars = {'kp_1': 'kp_2', 'kp_2': 'kp_1'}\n",
    "        PCargs.freepars = [freepars[PCargs.freepars[0]]]\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        PCargs.initpoint = {'lac_i': 1,\n",
    "                    'tet_r': .001,\n",
    "                    PCargs.freepars[0]:0.0001}\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "            LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        except:\n",
    "            print('fail')\n",
    "            LP1 = None\n",
    "            LP2 = None\n",
    "\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('give up')\n",
    "        PCargs.MaxStepSize = .1\n",
    "        freepars = {'kp_1': 'kp_2', 'kp_2': 'kp_1'}\n",
    "        PCargs.freepars = [freepars[PCargs.freepars[0]]]\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        PCargs.initpoint = {'lac_i': 1,\n",
    "                    'tet_r': .001,\n",
    "                    PCargs.freepars[0]:0.0001}\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "            LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        except:\n",
    "            print('fail')\n",
    "            LP1 = None\n",
    "            LP2 = None\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('final try')\n",
    "        PCargs.MaxStepSize = max(params_dict['kdeg_1'], params_dict['kdeg_2'])/10*min(params_dict['kdiss_1'], params_dict['kdiss_2'])*10000\n",
    "        PCargs.freepars = [freepars[PCargs.freepars[0]]]\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        PCargs.initpoint = {'lac_i': 1,\n",
    "                    'tet_r': .001,\n",
    "                    PCargs.freepars[0]:0.0001}\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "            LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        except:\n",
    "            print('fail')\n",
    "            LP1 = None\n",
    "            LP2 = None\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('final try')\n",
    "        PCargs.MaxStepSize = max(params_dict['kdeg_1'], params_dict['kdeg_2'])/10*min(params_dict['kdiss_1'], params_dict['kdiss_2'])*10000\n",
    "        PCargs.freepars = [freepars[PCargs.freepars[0]]]\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        PCargs.initpoint = {'lac_i': 1,\n",
    "                    'tet_r': .001,\n",
    "                    PCargs.freepars[0]:0.0001}\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "            LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "            LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "        except:\n",
    "            print('fail')\n",
    "            LP1 = None\n",
    "            LP2 = None\n",
    "\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "            print('hmmm')\n",
    "\n",
    "            PCargs.initpoint = {'lac_i': 10000,\n",
    "                        'tet_r': 0.1,\n",
    "                        PCargs.freepars[0]:0.0001}\n",
    "            con_ode_sys.newCurve(PCargs)\n",
    "            try:\n",
    "                con_ode_sys['EQ1'].backward()\n",
    "                con_ode_sys['EQ1'].backward()\n",
    "                LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "                LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "            except:\n",
    "                print('fail')\n",
    "                LP1 = None\n",
    "                LP2 = None\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('whatever')\n",
    "        freepars = {'kp_1': 'kp_2', 'kp_2': 'kp_1'}\n",
    "        PCargs.freepars = [freepars[PCargs.freepars[0]]]\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "        PCargs.initpoint = {'lac_i': 0.001,\n",
    "                    'tet_r': 0.1,\n",
    "                    PCargs.freepars[0]:0.0001}\n",
    "        con_ode_sys.newCurve(PCargs)\n",
    "    try:\n",
    "        con_ode_sys['EQ1'].forward()\n",
    "        con_ode_sys['EQ1'].forward()\n",
    "        con_ode_sys['EQ1'].forward()\n",
    "        LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "        LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "    except:\n",
    "        print('fail')\n",
    "        LP1 = None\n",
    "        LP2 = None\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if len(LP_list) < 2:\n",
    "        print('entered again')\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].backward()\n",
    "        except:\n",
    "            print('No')\n",
    "        try:\n",
    "            con_ode_sys['EQ1'].forward()\n",
    "        except:\n",
    "            print('No')\n",
    "        LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "        LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if LP_list:\n",
    "        if con_ode_sys['EQ1'].freepars[0]=='kp_1':\n",
    "            LP_list = list(reversed(LP_list))\n",
    "        init_point = LP_list[0]\n",
    "    else:\n",
    "        init_point = None\n",
    "        \n",
    "    return con_ode_sys, init_point\n",
    "\n",
    "# This function processes the continuity curbves and generates robustness values as the fraction of area bound by the continuity curves\n",
    "def process_continuation_results(x=[], y=[], params_dict={}, threshold=1000):\n",
    "    min_x = min(x)\n",
    "    min_y = min(y)\n",
    "\n",
    "    if (y[0] - min(y))/(x[0] - min(x)) > (y[-1] - min(y))/(x[-1] - min(x)):#Condition to check if upper curve begins first\n",
    "        upper_x = np.sort(x[:np.argmin(x)+1])\n",
    "        upper_y = np.sort(y[:np.argmin(x)+1])\n",
    "        lower_x = np.sort(x[np.argmin(x):])\n",
    "        lower_y = np.sort(y[np.argmin(x):])\n",
    "    else:\n",
    "        lower_x = np.sort(x[:np.argmin(x)+1])\n",
    "        lower_y = np.sort(y[:np.argmin(x)+1])\n",
    "        upper_x = np.sort(x[np.argmin(x):])\n",
    "        upper_y = np.sort(y[np.argmin(x):])\n",
    "\n",
    "    raw_lower_x = lower_x\n",
    "    raw_lower_y = lower_y\n",
    "    raw_upper_x = upper_x\n",
    "    raw_upper_y = upper_y\n",
    "\n",
    "    #Clearing any duplicate entries in x or y - helps clear up probs with interpolation\n",
    "    u, indices = np.unique(lower_x, return_index=True)\n",
    "    lower_x = lower_x[indices]\n",
    "    lower_y = lower_y[indices]\n",
    "    u, indices = np.unique(lower_y, return_index=True)\n",
    "    lower_x = lower_x[indices]\n",
    "    lower_y = lower_y[indices]\n",
    "\n",
    "    u, indices = np.unique(upper_x, return_index=True)\n",
    "    upper_x = upper_x[indices]\n",
    "    upper_y = upper_y[indices]\n",
    "    u, indices = np.unique(upper_y, return_index=True)\n",
    "    upper_x = upper_x[indices]\n",
    "    upper_y = upper_y[indices]\n",
    "\n",
    "    try:\n",
    "        lower_interp = interpolate(lower_x, lower_y, k=3)\n",
    "        upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "    except:\n",
    "        results_dict = {'params': params_dict,\n",
    "            'robustness': 0,\n",
    "            'lower_x': [],\n",
    "            'lower_y': [],\n",
    "            'upper_x': [],\n",
    "            'upper_y': [],\n",
    "            'raw_lower_x': [],\n",
    "            'raw_lower_y': [],\n",
    "            'raw_upper_x': [],\n",
    "            'raw_upper_y': [],\n",
    "            'raw_x': x,\n",
    "            'raw_y': y,\n",
    "            'status': False}\n",
    "        return results_dict\n",
    "\n",
    "\n",
    "    if lower_interp(threshold) < 0:\n",
    "        lower_x = lower_x[:-1]\n",
    "        lower_y = lower_y[:-1]\n",
    "\n",
    "    if upper_interp(threshold) < 0:\n",
    "        upper_x = upper_x[:-1]\n",
    "        upper_y = upper_y[:-1]\n",
    "\n",
    "    if upper_interp(threshold) < threshold and upper_interp(threshold) > 0: #Upper curve does not hit upper threshold -> need to cut short everything at x(kp1)=100\n",
    "\n",
    "        lower_interp = interpolate(lower_x, lower_y, k=3)\n",
    "        upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "\n",
    "        lower_x = np.linspace(min(lower_x), threshold, 1000)\n",
    "        lower_y = lower_interp(lower_x)\n",
    "        upper_x = np.linspace(min(upper_x), threshold, 1000)\n",
    "        upper_y = upper_interp(upper_x)\n",
    "\n",
    "    elif lower_interp(threshold) > threshold: #Lower curve hits upper threshold -> Need to cut short everything at y(kp2)=100\n",
    "        lower_interp = interpolate(lower_y, lower_x, k=3)\n",
    "        upper_interp = interpolate(upper_y, upper_x, k=3)\n",
    "\n",
    "        if lower_interp(threshold) > threshold:#Irregular interpolation. Deal by keeping this but truncating appropriately\n",
    "            lower_y = np.linspace(min(lower_y), threshold, 1000)\n",
    "            lower_x = lower_interp(np.linspace(min(lower_y), threshold, 1000))\n",
    "            u, indices = np.unique(lower_x, return_index=True)\n",
    "            lower_x = lower_x[indices]\n",
    "            lower_y = lower_y[indices]\n",
    "            lower_interp = interpolate(lower_x, lower_y, \n",
    "                                       k=3)\n",
    "            lower_x = np.linspace(min(lower_x), threshold, 1000)\n",
    "            lower_y = lower_interp(lower_x)\n",
    "        else:\n",
    "\n",
    "            lower_y = np.linspace(min(lower_y), threshold, 1000)\n",
    "            lower_x = lower_interp(lower_y)\n",
    "\n",
    "        if upper_interp(threshold) > lower_interp(threshold):#irregular case\n",
    "            upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "            upper_x = np.linspace(min(upper_x), 5*max(upper_x), 1000)\n",
    "            upper_y = upper_interp(upper_x)\n",
    "            u, indices = np.unique(upper_y, return_index=True)\n",
    "            upper_x = upper_x[indices]\n",
    "            upper_y = upper_y[indices]\n",
    "            upper_interp = interpolate(upper_y, upper_x, k=3)  \n",
    "\n",
    "\n",
    "        upper_y = np.linspace(min(upper_y), threshold, 1000)\n",
    "        upper_x = upper_interp(upper_y)\n",
    "        upper_y = np.append(upper_y, [threshold for i in range(100)])\n",
    "        upper_x = np.append(upper_x, np.linspace(max(upper_x), max(lower_x), 100))\n",
    "\n",
    "    elif lower_interp(threshold) < threshold: # A normal continuity curve - lower curve intersects x=threshold and upper curve intersects y=threshold\n",
    "        lower_interp = interpolate(lower_y, lower_x, k=3)\n",
    "        upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "\n",
    "\n",
    "        lower_y = np.linspace(min(lower_y), threshold, 1000)\n",
    "        lower_x = lower_interp(lower_y)\n",
    "        u, indices = np.unique(lower_x, return_index=True)\n",
    "        lower_x = lower_x[indices]\n",
    "        lower_y = lower_y[indices]\n",
    "        lower_interp = interpolate(lower_x, \n",
    "                               lower_y, \n",
    "                               k=3)\n",
    "        lower_x = np.linspace(min(lower_x), threshold, 1000)\n",
    "        lower_y = lower_interp(lower_x)\n",
    "\n",
    "        if upper_interp(threshold)<0 and lower_interp(threshold)>0:\n",
    "\n",
    "            upper_x = np.linspace(min(upper_x), 5*max(upper_x), 1000)\n",
    "            upper_y = upper_interp(upper_x)\n",
    "            u, indices = np.unique(upper_y, return_index=True)\n",
    "            upper_x = upper_x[indices]\n",
    "            upper_y = upper_y[indices]\n",
    "            upper_interp = interpolate(upper_y, upper_x, k=3)  \n",
    "            upper_y = np.linspace(min(upper_y), 2*max(upper_y), 1000)\n",
    "            upper_x = upper_interp(upper_y)\n",
    "            u, indices = np.unique(upper_x, return_index=True)\n",
    "            upper_x = upper_x[indices]\n",
    "            upper_y = upper_y[indices]\n",
    "            upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "\n",
    "                \n",
    "            if upper_interp(threshold) > threshold:\n",
    "                upper_x = np.linspace(min(upper_x), threshold, 1000)\n",
    "                upper_y = upper_interp(upper_x)\n",
    "                upper_y = np.array([element if element<threshold else threshold for element in upper_y])\n",
    "            if upper_interp(threshold) < threshold and upper_interp(threshold):\n",
    "                upper_x = np.linspace(min(upper_x), 5*max(upper_x), 1000)\n",
    "                upper_y = upper_interp(upper_x)\n",
    "                u, indices = np.unique(upper_y, return_index=True)\n",
    "                upper_x = upper_x[indices]\n",
    "                upper_y = upper_y[indices]\n",
    "                upper_interp = interpolate(upper_y, upper_x, k=3)\n",
    "                upper_y = np.linspace(min(upper_y), threshold, 1000)\n",
    "                upper_x = upper_interp(upper_y)\n",
    "                upper_x = np.append(upper_x, np.linspace(max(upper_x), threshold, 100)[1:])\n",
    "                upper_y = np.append(upper_y, [threshold]*len(np.linspace(max(upper_x), threshold, 100)[1:]))\n",
    "\n",
    "            if (upper_x[-1]<0) or (upper_y[-1]<0):\n",
    "\n",
    "                upper_interp = interpolate(raw_upper_x, raw_upper_y, k=3)\n",
    "                upper_x = np.linspace(min(raw_upper_x), 5*max(raw_upper_x), 1000)\n",
    "                upper_y = upper_interp(upper_x)\n",
    "                u, indices = np.unique(upper_y, return_index=True)\n",
    "                upper_x = upper_x[indices]\n",
    "                upper_y = upper_y[indices]\n",
    "                upper_x = np.linspace(min(upper_x), 5*max(upper_x), 1000)\n",
    "                upper_y = upper_interp(upper_x)\n",
    "                u, indices = np.unique(upper_y, return_index=True)\n",
    "                upper_x = upper_x[indices]\n",
    "                upper_y = upper_y[indices]\n",
    "                upper_interp = interpolate(upper_y, upper_x, k=3) \n",
    "                upper_y = np.linspace(min(upper_y), threshold, 1000)\n",
    "                upper_x = upper_interp(upper_y)\n",
    "                upper_x = np.append(upper_x, np.linspace(max(upper_x), threshold, 100)[1:])\n",
    "                upper_y = np.append(upper_y, [threshold]*len(np.linspace(max(upper_x), threshold, 100)[1:]))\n",
    "        else:\n",
    "            upper_x = np.linspace(min(upper_x), threshold, 1000)\n",
    "            upper_y = upper_interp(upper_x)\n",
    "            upper_y = np.array([element if element<threshold else threshold for element in upper_y])\n",
    "\n",
    "    else:\n",
    "        results_dict = {'params': params_dict,\n",
    "            'robustness': 0,\n",
    "            'lower_x': [],\n",
    "            'lower_y': [],\n",
    "            'upper_x': [],\n",
    "            'upper_y': [],\n",
    "            'raw_lower_x': [],\n",
    "            'raw_lower_y': [],\n",
    "            'raw_upper_x': [],\n",
    "            'raw_upper_y': [],\n",
    "            'raw_x': x,\n",
    "            'raw_y': y,\n",
    "            'status': True}\n",
    "        return results_dict\n",
    "\n",
    "\n",
    "    robustness = np.trapz(upper_y, upper_x) - np.trapz(lower_y, lower_x)\n",
    "    if robustness < 0:\n",
    "        robustness = 0\n",
    "\n",
    "\n",
    "\n",
    "    results_dict = {'params': params_dict,\n",
    "                    'robustness': robustness,\n",
    "                    'lower_x': lower_x,\n",
    "                    'lower_y': lower_y,\n",
    "                    'upper_x': upper_x,\n",
    "                    'upper_y': upper_y,\n",
    "                    'raw_lower_x': raw_lower_x,\n",
    "                    'raw_lower_y': raw_lower_y,\n",
    "                    'raw_upper_x': raw_upper_x,\n",
    "                    'raw_upper_y': raw_upper_y,\n",
    "                    'raw_x': x,\n",
    "                    'raw_y': y,\n",
    "                    'status': True}\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def simple_toggle_robustness_repeat(params_dict, threshold):\n",
    "    \n",
    "    con_ode_sys, init_point = generate_equilibrium_curve(params_dict, threshold)\n",
    "    PCargs = args(name='robustness', type='LP-C', force=True)\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if LP_list:\n",
    "        PCargs.initpoint = 'EQ1:'+init_point\n",
    "        PCargs.freepars = ['kp_1','kp_2']\n",
    "        PCargs.MaxNumPoints = 500\n",
    "        PCargs.MinStepSize = 0.0001\n",
    "        PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(init_point)[con_ode_sys['EQ1'].freepars[0]]/100\n",
    "        if PCargs.MaxStepSize < 10:\n",
    "            PCargs.MaxStepSize = 10\n",
    "        attempts = 0\n",
    "        success = False\n",
    "        while not success and attempts < 3:\n",
    "            attempts += 1\n",
    "            print('attempts= ', attempts)\n",
    "            try:\n",
    "                con_ode_sys.newCurve(PCargs)\n",
    "                try:\n",
    "                    con_ode_sys['robustness'].forward()\n",
    "                    con_ode_sys['robustness'].backward()\n",
    "                except:\n",
    "                    con_ode_sys['robustness'].backward()\n",
    "                    con_ode_sys['robustness'].forward()\n",
    "                success=True\n",
    "            except:\n",
    "                if len(LP_list) > 1:\n",
    "                    init_point = [LP for LP in LP_list if LP!=init_point][0]\n",
    "                    PCargs.initpoint = 'EQ1:'+init_point\n",
    "\n",
    "\n",
    "                PCargs.MaxNumPoints = int(PCargs.MaxNumPoints * 1.5)\n",
    "                PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(init_point)[con_ode_sys['EQ1'].freepars[0]]/100\n",
    "                if PCargs.MaxStepSize < 10:\n",
    "                    PCargs.MaxStepSize = 20\n",
    "                PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "\n",
    "                x = []\n",
    "                y = []\n",
    "                continue\n",
    "            x = con_ode_sys['robustness'].sol['kp_1']\n",
    "            y = con_ode_sys['robustness'].sol['kp_2']\n",
    "            print(\"x=\", x, 'y= ',y)\n",
    "            if len(x) > 2 and len(y) > 2:\n",
    "                if (x[0] >= x[1]) or (y[0] >= y[1]):\n",
    "                    x = x[1:]\n",
    "                    y = y[1:]\n",
    "                if (x[-1] <= x[-2]) or (y[-1] <= y[-2]):\n",
    "                    y = y[:-1]\n",
    "                    x = x[:-1]\n",
    "                print(x[0], y[0])\n",
    "                print(x[-1], y[-1])\n",
    "                gradients = np.gradient(y,x)\n",
    "                \n",
    "                if np.argmin(x) in range(1,len(x)-1) or np.argmin(y) in range(1, len(y)-1):\n",
    "                    \n",
    "                    if (min(x) > threshold) or (min(y) > threshold):\n",
    "                        print('broke')\n",
    "                        break\n",
    "                print(\"Beginning Gradient: \", gradients[0]/gradients[1])\n",
    "                print(\"Ending Gradient: \", gradients[-1]/gradients[-2])\n",
    "                if (gradients[0]/gradients[1]<0.95 or gradients[0]/gradients[1]>1.05): #This means closed curve at beginning. Trim first point\n",
    "                    print('closed at beginning')\n",
    "                    x = x[1:]\n",
    "                    y = y[1:]\n",
    "                    PCargs.MaxNumPoints = int(PCargs.MaxNumPoints * 2)\n",
    "                    PCargs.MaxStepSize = PCargs.MaxStepSize/10\n",
    "                    PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "                    if attempts == 3:\n",
    "                        success = True\n",
    "                    else:\n",
    "                        print('repeating because closed at beginning')\n",
    "                        success = False\n",
    "                    continue\n",
    "\n",
    "                elif (gradients[-1]/gradients[-2]<0.95 or gradients[-1]/gradients[-2]>1.05):\n",
    "                    print('closed at end')\n",
    "\n",
    "                    if attempts == 3:\n",
    "                        success = True\n",
    "                    else:\n",
    "                        print('repeating because closed at end')\n",
    "                        success = False\n",
    "                    x = x[:-1]\n",
    "                    y = y[:-1]\n",
    "                    PCargs.MaxNumPoints = int(PCargs.MaxNumPoints * 2)\n",
    "                    PCargs.MaxStepSize = PCargs.MaxStepSize/10\n",
    "                    PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "                    continue\n",
    "\n",
    "\n",
    "                elif np.argmin(x) in range(0,3) or np.argmin(x) in range(len(x)-3,len(x)):\n",
    "                    PCargs.MaxNumPoints = int(PCargs.MaxNumPoints*1.5)\n",
    "                    PCargs.MaxStepSize = max(min(x), min(y))/100\n",
    "                    if PCargs.MaxStepSize < 10:\n",
    "                        PCargs.MaxStepSize = 20 \n",
    "                    PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    print('repeating because min is too close to ends of list')\n",
    "                    success = False\n",
    "\n",
    "                elif not ((x[0] > threshold or y[0] > threshold) and \n",
    "                            (x[-1] > threshold or y[-1] > threshold)):\n",
    "\n",
    "                    PCargs.MaxNumPoints = int(PCargs.MaxNumPoints*1.5)\n",
    "                    PCargs.MaxStepSize = max(min(x), min(y))/100\n",
    "                    if PCargs.MaxStepSize < 10:\n",
    "                        PCargs.MaxStepSize = 20\n",
    "                        \n",
    "                    PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "                    if attempts == 3:\n",
    "                        success = True\n",
    "                    else:\n",
    "                        print('repeating because curve is not exactly complete')\n",
    "                        success = False\n",
    "\n",
    "        if len(x)!=0 and len(y)!=0:\n",
    "            if not (min(x)<=threshold and min(y)<=threshold):\n",
    "                \n",
    "                success=False\n",
    "                \n",
    "        if success:\n",
    "            results_dict = process_continuation_results(x, y, params_dict)\n",
    "            \n",
    "        else:\n",
    "            results_dict = {'params': params_dict,\n",
    "                            'robustness': 0,\n",
    "                            'lower_x': [],\n",
    "                            'lower_y': [],\n",
    "                            'upper_x': [],\n",
    "                            'upper_y': [],\n",
    "                            'raw_lower_x': [],\n",
    "                            'raw_lower_y': [],\n",
    "                            'raw_upper_x': [],\n",
    "                            'raw_upper_y': [],\n",
    "                            'raw_x': x,\n",
    "                            'raw_y': y,\n",
    "                            'status': False}\n",
    "    else:\n",
    "        results_dict = {'params': params_dict,\n",
    "                'robustness': 0,\n",
    "                'lower_x': [],\n",
    "                'lower_y': [],\n",
    "                'upper_x': [],\n",
    "                'upper_y': [],\n",
    "                'raw_lower_x': [],\n",
    "                'raw_lower_y': [],\n",
    "                'raw_upper_x': [],\n",
    "                'raw_upper_y': [],\n",
    "                'raw_x': [],\n",
    "                'raw_y': [],\n",
    "                'status': False}\n",
    "    return results_dict\n",
    "\n",
    "    \n",
    "def simple_toggle_robustness(params_dict, threshold):\n",
    "    \n",
    "    con_ode_sys, init_point = generate_equilibrium_curve(params_dict, threshold)\n",
    "    PCargs = args(name='robustness', type='LP-C', force=True)\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "     \n",
    "    if LP_list:\n",
    "        PCargs.initpoint = 'EQ1:'+init_point\n",
    "        PCargs.freepars = ['kp_1','kp_2']\n",
    "        PCargs.MaxNumPoints = 500\n",
    "        PCargs.MinStepSize = 0.0001\n",
    "        PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(init_point)[con_ode_sys['EQ1'].freepars[0]]/100\n",
    "        if PCargs.MaxStepSize < 10:\n",
    "            PCargs.MaxStepSize = 10\n",
    "        attempts = 0\n",
    "        success = False\n",
    "        while not success and attempts < 3:\n",
    "            attempts += 1\n",
    "            print('attempts= ', attempts)\n",
    "            try:\n",
    "                con_ode_sys.newCurve(PCargs)\n",
    "                try:\n",
    "                    con_ode_sys['robustness'].forward()\n",
    "                    con_ode_sys['robustness'].backward()\n",
    "                except:\n",
    "                    con_ode_sys['robustness'].backward()\n",
    "                    con_ode_sys['robustness'].forward()\n",
    "                success=True\n",
    "            except:\n",
    "                if len(LP_list) > 1:\n",
    "                    init_point = [LP for LP in LP_list if LP!=init_point][0]\n",
    "                    PCargs.initpoint = 'EQ1:'+init_point\n",
    "\n",
    "                PCargs.MaxNumPoints = int(PCargs.MaxNumPoints * 1.5)\n",
    "                PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(init_point)[con_ode_sys['EQ1'].freepars[0]]/100\n",
    "                if PCargs.MaxStepSize < 10:\n",
    "                    PCargs.MaxStepSize = 20\n",
    "                PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "\n",
    "                x = []\n",
    "                y = []\n",
    "                continue\n",
    "            x = con_ode_sys['robustness'].sol['kp_1']\n",
    "            y = con_ode_sys['robustness'].sol['kp_2']\n",
    "        \n",
    "\n",
    "            if len(x) > 2 and len(y) > 2:\n",
    "                if (x[0] >= x[1]) or (y[0] >= y[1]):\n",
    "                    x = x[1:]\n",
    "                    y = y[1:]\n",
    "                if (x[-1] <= x[-2]) or (y[-1] <= y[-2]):\n",
    "                    y = y[:-1]\n",
    "                    x = x[:-1]\n",
    "                print(x[0], y[0])\n",
    "                print(x[-1], y[-1])\n",
    "                gradients = np.gradient(y,x)\n",
    "                if np.argmin(x) in range(1,len(x)-1) or np.argmin(y) in range(1, len(y)-1):\n",
    "                    if min(x) > threshold or min(y) > threshold:\n",
    "                        print('broke')\n",
    "                        break\n",
    "                if (gradients[0]/gradients[1]<0.95 or gradients[0]/gradients[1]>1.05): #This means closed curve at beginning. Trim first point\n",
    "                    x = x[1:]\n",
    "                    y = y[1:]\n",
    "                    print('entered closed curve at beginning')\n",
    "                    if len(LP_list) > 1:\n",
    "                        init_point = [LP for LP in LP_list if LP!=init_point][0]\n",
    "                        PCargs.initpoint = 'EQ1:'+init_point\n",
    "                        PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(init_point)[con_ode_sys['EQ1'].freepars[0]]/100\n",
    "                    else:\n",
    "                        PCargs.MaxNumPoints = int(PCargs.MaxNumPoints * 1.5)\n",
    "                        PCargs.MaxStepSize = PCargs.MaxStepSize/10\n",
    "                    \n",
    "                    if PCargs.MaxStepSize < 10:\n",
    "                        PCargs.MaxStepSize = 20\n",
    "                    PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "                    if attempts == 3:\n",
    "                        success = True\n",
    "                    else:\n",
    "                        success = False\n",
    "                    continue\n",
    "\n",
    "                elif (gradients[-1]/gradients[-2]<0.95 or gradients[-1]/gradients[-2]>1.05):\n",
    "                    print('entered closed curve at end')\n",
    "\n",
    "                    if attempts == 3:\n",
    "                        success = True\n",
    "                    else:\n",
    "                        success = False\n",
    "                    x = x[:-1]\n",
    "                    y = y[:-1]\n",
    "\n",
    "                    if len(LP_list) > 1:\n",
    "                        init_point = [LP for LP in LP_list if LP!=init_point][0]\n",
    "                        PCargs.initpoint = 'EQ1:'+init_point\n",
    "                        PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(init_point)[con_ode_sys['EQ1'].freepars[0]]/100\n",
    "                    else:\n",
    "                        PCargs.MaxNumPoints = int(PCargs.MaxNumPoints * 1.5)\n",
    "                        PCargs.MaxStepSize = PCargs.MaxStepSize/10\n",
    "                    \n",
    "                    if PCargs.MaxStepSize < 10:\n",
    "                        PCargs.MaxStepSize = 20\n",
    "                    PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "\n",
    "                    continue\n",
    "\n",
    "\n",
    "                elif np.argmin(x) in range(0,3) or np.argmin(x) in range(len(x)-3,len(x)):\n",
    "                    PCargs.MaxNumPoints = int(PCargs.MaxNumPoints*1.5)\n",
    "                    PCargs.MaxStepSize = max(min(x), min(y))/100\n",
    "                    if PCargs.MaxStepSize < 10:\n",
    "                        PCargs.MaxStepSize = 20\n",
    "                    PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    success = False\n",
    "\n",
    "                elif not ((x[0] > threshold or y[0] > threshold) and \n",
    "                            (x[-1] > threshold or y[-1] > threshold)):\n",
    "                    print(x[0], y[0])\n",
    "                    print(x[-1], y[-1])\n",
    "                    PCargs.MaxNumPoints = int(PCargs.MaxNumPoints*1.5)\n",
    "                    PCargs.MaxStepSize = max(min(x), min(y))/100\n",
    "                    if PCargs.MaxStepSize < 10:\n",
    "                        PCargs.MaxStepSize = 20\n",
    "                    PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "                    print(PCargs.MaxNumPoints, PCargs.MaxStepSize, PCargs.MinStepSize)\n",
    "                    if attempts == 3:\n",
    "                        success = True\n",
    "                    else:\n",
    "                        success = False\n",
    "                        \n",
    "        if len(x)!=0 and len(y)!=0:\n",
    "            if not (min(x)<=threshold and min(y)<=threshold):\n",
    "                success=False\n",
    "                \n",
    "        if success:\n",
    "            results_dict = process_continuation_results(x, y, params_dict)\n",
    "            \n",
    "        else:\n",
    "            results_dict = {'params': params_dict,\n",
    "                            'robustness': 0,\n",
    "                            'lower_x': [],\n",
    "                            'lower_y': [],\n",
    "                            'upper_x': [],\n",
    "                            'upper_y': [],\n",
    "                            'raw_lower_x': [],\n",
    "                            'raw_lower_y': [],\n",
    "                            'raw_upper_x': [],\n",
    "                            'raw_upper_y': [],\n",
    "                            'raw_x': x,\n",
    "                            'raw_y': y,\n",
    "                            'status': False}\n",
    "    else:\n",
    "        results_dict = {'params': params_dict,\n",
    "                'robustness': 0,\n",
    "                'lower_x': [],\n",
    "                'lower_y': [],\n",
    "                'upper_x': [],\n",
    "                'upper_y': [],\n",
    "                'raw_lower_x': [],\n",
    "                'raw_lower_y': [],\n",
    "                'raw_upper_x': [],\n",
    "                'raw_upper_y': [],\n",
    "                'raw_x': [],\n",
    "                'raw_y': [],\n",
    "                'status': False}\n",
    "    return results_dict\n",
    "    \n",
    "def simple_toggle_robustness_final(params_dict, threshold):\n",
    "    \n",
    "    con_ode_sys, init_point = generate_equilibrium_curve(params_dict, threshold)\n",
    "    PCargs = args(name='robustness', type='LP-C', force=True)\n",
    "    LP_list = get_limit_points(con_ode_sys)\n",
    "    if LP_list:\n",
    "        PCargs.initpoint = 'EQ1:'+init_point\n",
    "        PCargs.freepars = ['kp_1','kp_2']\n",
    "        PCargs.MaxNumPoints = 500\n",
    "        PCargs.MinStepSize = 0.0001\n",
    "        PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(init_point)[con_ode_sys['EQ1'].freepars[0]]/100\n",
    "        if PCargs.MaxStepSize < 10:\n",
    "            PCargs.MaxStepSize = 10\n",
    "        attempts = 0\n",
    "        success = False\n",
    "        while not success and attempts < 3:\n",
    "            attempts += 1\n",
    "            print('attempts= ', attempts)\n",
    "            try:\n",
    "                con_ode_sys.newCurve(PCargs)\n",
    "                try:\n",
    "                    con_ode_sys['robustness'].forward()\n",
    "                    con_ode_sys['robustness'].backward()\n",
    "                except:\n",
    "                    con_ode_sys['robustness'].backward()\n",
    "                    con_ode_sys['robustness'].forward()\n",
    "                success=True\n",
    "            except:\n",
    "                print('entered except')\n",
    "                if len(LP_list) > 1:\n",
    "                    init_point = [LP for LP in LP_list if LP!=init_point][0]\n",
    "                    PCargs.initpoint = 'EQ1:'+init_point\n",
    "\n",
    "                PCargs.MaxNumPoints = int(PCargs.MaxNumPoints * 1)\n",
    "                PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(init_point)[con_ode_sys['EQ1'].freepars[0]]/100\n",
    "                if PCargs.MaxStepSize < 10:\n",
    "                    PCargs.MaxStepSize = 20\n",
    "                PCargs.MinStepSize = PCargs.MinStepSize / 10\n",
    "\n",
    "                x = []\n",
    "                y = []\n",
    "                continue\n",
    "            x = con_ode_sys['robustness'].sol['kp_1']\n",
    "            y = con_ode_sys['robustness'].sol['kp_2']\n",
    "\n",
    "        if len(x)!=0 and len(y)!=0:\n",
    "            if not (min(x)<=threshold and min(y)<=threshold):\n",
    "                success=False\n",
    "                \n",
    "        if success:\n",
    "            results_dict = process_continuation_results(x, y, params_dict)\n",
    "            \n",
    "        else:\n",
    "            results_dict = {'params': params_dict,\n",
    "                            'robustness': 0,\n",
    "                            'lower_x': [],\n",
    "                            'lower_y': [],\n",
    "                            'upper_x': [],\n",
    "                            'upper_y': [],\n",
    "                            'raw_lower_x': [],\n",
    "                            'raw_lower_y': [],\n",
    "                            'raw_upper_x': [],\n",
    "                            'raw_upper_y': [],\n",
    "                            'raw_x': x,\n",
    "                            'raw_y': y,\n",
    "                            'status': False}\n",
    "    else:\n",
    "        results_dict = {'params': params_dict,\n",
    "                'robustness': 0,\n",
    "                'lower_x': [],\n",
    "                'lower_y': [],\n",
    "                'upper_x': [],\n",
    "                'upper_y': [],\n",
    "                'raw_lower_x': [],\n",
    "                'raw_lower_y': [],\n",
    "                'raw_upper_x': [],\n",
    "                'raw_upper_y': [],\n",
    "                'raw_x': [],\n",
    "                'raw_y': [],\n",
    "                'status': False}\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def new_simple_toggle_robustness(params_dict, threshold):\n",
    "    \n",
    "    \n",
    "    \n",
    "    con_ode_sys, init_point = generate_equilibrium_curve(params_dict, threshold)\n",
    "    PCargs = args(name='robustness', type='LP-C', force=True)\n",
    "    \n",
    "\n",
    "    LP1 = con_ode_sys['EQ1'].getSpecialPoint('LP1')\n",
    "    LP2 = con_ode_sys['EQ1'].getSpecialPoint('LP2')\n",
    "    LP3 = con_ode_sys['EQ1'].getSpecialPoint('LP3')\n",
    "    LP4 = con_ode_sys['EQ1'].getSpecialPoint('LP4')\n",
    "    LP_list = [LP for LP in [LP1, LP2, LP3, LP4] if LP and LP[con_ode_sys['EQ1'].freepars[0]]>0]\n",
    "    unique_lp_vals = list(set([np.round(LP[con_ode_sys['EQ1'].freepars[0]], 5) for LP in LP_list]))\n",
    "    final_lp_list = []\n",
    "    for LP in LP_list:\n",
    "        if np.round(LP[con_ode_sys['EQ1'].freepars[0]], 5) in unique_lp_vals:\n",
    "            unique_lp_vals.remove(np.round(LP[con_ode_sys['EQ1'].freepars[0]], 5))\n",
    "            final_lp_list.append(LP.labels['LP']['name'])\n",
    "    LP_list = final_lp_list\n",
    "    LP_list = sorted(LP_list, key=lambda x: con_ode_sys['EQ1'].getSpecialPoint(x)[con_ode_sys['EQ1'].freepars[0]])\n",
    "\n",
    "    \n",
    "    if con_ode_sys['EQ1'].freepars[0]=='kp_1':\n",
    "        LP_list = list(reversed(LP_list))\n",
    "\n",
    "    if len(LP_list) == 2:\n",
    "\n",
    "        x = [None,None]\n",
    "        y = [None,None]\n",
    "        for i, LP in enumerate(LP_list):\n",
    "            PCargs.initpoint = 'EQ1:'+LP\n",
    "            PCargs.freepars = ['kp_1','kp_2']\n",
    "            PCargs.MaxNumPoints = 100\n",
    "            PCargs.MinStepSize = 0.00001\n",
    "            PCargs.MaxStepSize = con_ode_sys['EQ1'].getSpecialPoint(LP)[con_ode_sys['EQ1'].freepars[0]]\n",
    "            if PCargs.MaxStepSize >0.1:\n",
    "                PCargs.MaxStepSize = 0.1\n",
    "            attempts = 0\n",
    "            success = False\n",
    "            while not success and attempts < 3:\n",
    "                attempts += 1\n",
    "                print('attempts= ', attempts)\n",
    "                try:\n",
    "                    con_ode_sys.newCurve(PCargs)\n",
    "                    try:\n",
    "                        con_ode_sys['robustness'].forward()\n",
    "                        con_ode_sys['robustness'].backward()\n",
    "                    except:\n",
    "                        con_ode_sys['robustness'].backward()\n",
    "                        con_ode_sys['robustness'].forward()\n",
    "                    success=True\n",
    "                except:\n",
    "                    results_dict = {'params': params_dict,\n",
    "                        'robustness': 0,\n",
    "                        'lower_x': [],\n",
    "                        'lower_y': [],\n",
    "                        'upper_x': [],\n",
    "                        'upper_y': [],\n",
    "                        'raw_lower_x': [],\n",
    "                        'raw_lower_y': [],\n",
    "                        'raw_upper_x': [],\n",
    "                        'raw_upper_y': [],\n",
    "                        'raw_x': x,\n",
    "                        'raw_y': y,\n",
    "                        'status': 'RETRY'}\n",
    "                    return results_dict                    \n",
    "                    break\n",
    "                x[i] = con_ode_sys['robustness'].sol['kp_1']\n",
    "                y[i] = con_ode_sys['robustness'].sol['kp_2']\n",
    "\n",
    "                if len(x[i]) > 2 and len(y[i]) > 2:\n",
    "                    gradients = np.gradient(y[i],x[i])\n",
    "                    if (gradients[0]/gradients[1]<0.9 or gradients[0]/gradients[1]>1.1): #This means closed curve at beginning. Trim first point\n",
    "                        x[i] = x[i][2:]\n",
    "                        y[i] = y[i][2:]\n",
    "                        PCargs.MaxNumPoints = int(PCargs.MaxNumPoints*2)\n",
    "                        PCargs.MaxStepSize = PCargs.MaxStepSize/10\n",
    "                        if attempts == 3:\n",
    "                            success = True\n",
    "                        else:\n",
    "                            success = False\n",
    "                        continue\n",
    "                    elif (gradients[-1]/gradients[-2]<0.9 or gradients[-1]/gradients[-2]>1.1):\n",
    "                        if attempts == 3:\n",
    "                            success = True\n",
    "                        else:\n",
    "                            success = False\n",
    "                        x[i] = x[i][:-2]\n",
    "                        y[i] = y[i][:-2]\n",
    "                        PCargs.MaxNumPoints = int(PCargs.MaxNumPoints * 2)\n",
    "                        PCargs.MaxStepSize = PCargs.MaxStepSize/10\n",
    "                        continue\n",
    "\n",
    "\n",
    "        if (len(x[0])!=0) and (len(x[1])!=0):\n",
    "            min_x0 = min(x[0])\n",
    "            min_y0 = min(y[0])\n",
    "\n",
    "            min_x1 = min(x[1])\n",
    "            min_y1 = min(y[1])\n",
    "\n",
    "            if np.argmin(x[0]) not in [0, len(x[0])-1]:\n",
    "\n",
    "                if (y[0][0] - min_y0)/(x[0][0] - min_x0) > (y[0][-1] - min_y0)/(x[0][-1] - min_x0):#Condition to check if upper curve begins first\n",
    "                    lower_x = np.sort(x[0][np.argmin(x[0]):])\n",
    "                    lower_y = np.sort(y[0][np.argmin(x[0]):])\n",
    "                else:\n",
    "                    lower_x = np.sort(x[0][:np.argmin(x[0])+1])\n",
    "                    lower_y = np.sort(y[0][:np.argmin(x[0])+1])\n",
    "            else:\n",
    "                lower_x = np.sort(x[0])\n",
    "                lower_y = np.sort(y[0])\n",
    "\n",
    "\n",
    "            if np.argmin(x[1]) not in [0, len(x[1])-1]:\n",
    "\n",
    "                if (y[1][0] - min_y1)/(x[1][0] - min_x1) > (y[1][-1] - min_y1)/(x[1][-1] - min_x1):#Condition to check if upper curve begins first\n",
    "                    upper_x = np.sort(x[1][:np.argmin(x[1])+1])\n",
    "                    upper_y = np.sort(y[1][:np.argmin(x[1])+1])\n",
    "                else:\n",
    "                    upper_x = np.sort(x[1][np.argmin(x[1]):])\n",
    "                    upper_y = np.sort(y[1][np.argmin(x[1]):])\n",
    "            else:\n",
    "                upper_x = np.sort(x[1])\n",
    "                upper_y = np.sort(y[1])\n",
    "\n",
    "\n",
    "        raw_lower_x = lower_x\n",
    "        raw_lower_y = lower_y\n",
    "        raw_upper_x = upper_x\n",
    "        raw_upper_y = upper_y\n",
    "\n",
    "        #Clearing any duplicate entries in x or y - helps clear up probs with interpolation\n",
    "        u, indices = np.unique(lower_x, return_index=True)\n",
    "        lower_x = lower_x[indices]\n",
    "        lower_y = lower_y[indices]\n",
    "        u, indices = np.unique(lower_y, return_index=True)\n",
    "        lower_x = lower_x[indices]\n",
    "        lower_y = lower_y[indices]\n",
    "\n",
    "        u, indices = np.unique(upper_x, return_index=True)\n",
    "        upper_x = upper_x[indices]\n",
    "        upper_y = upper_y[indices]\n",
    "        u, indices = np.unique(upper_y, return_index=True)\n",
    "        upper_x = upper_x[indices]\n",
    "        upper_y = upper_y[indices]\n",
    "\n",
    "        try:\n",
    "            lower_interp = interpolate(lower_x, lower_y, k=3)\n",
    "            upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "        except:\n",
    "            results_dict = {'params': params_dict,\n",
    "                'robustness': 0,\n",
    "                'lower_x': [],\n",
    "                'lower_y': [],\n",
    "                'upper_x': [],\n",
    "                'upper_y': [],\n",
    "                'raw_lower_x': [],\n",
    "                'raw_lower_y': [],\n",
    "                'raw_upper_x': [],\n",
    "                'raw_upper_y': [],\n",
    "                'raw_x': x,\n",
    "                'raw_y': y,\n",
    "                'status': False}\n",
    "            return results_dict\n",
    "\n",
    "\n",
    "        if lower_interp(threshold) < 0:\n",
    "            lower_x = lower_x[:-1]\n",
    "            lower_y = lower_y[:-1]\n",
    "\n",
    "        if upper_interp(threshold) < 0:\n",
    "            upper_x = upper_x[:-1]\n",
    "            upper_y = upper_y[:-1]\n",
    "\n",
    "        if upper_interp(threshold) < threshold and upper_interp(threshold) > 0: #Upper curve does not hit upper threshold -> need to cut short everything at x(kp1)=100\n",
    "\n",
    "            lower_interp = interpolate(lower_x, lower_y, k=3)\n",
    "            upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "\n",
    "            lower_x = np.linspace(min(lower_x), threshold, 1000)\n",
    "            lower_y = lower_interp(lower_x)\n",
    "            upper_x = np.linspace(min(upper_x), threshold, 1000)\n",
    "            upper_y = upper_interp(upper_x)\n",
    "\n",
    "        elif lower_interp(threshold) > threshold: #Lower curve hits upper threshold -> Need to cut short everything at y(kp2)=100\n",
    "            lower_interp = interpolate(lower_y, lower_x, k=3)\n",
    "            upper_interp = interpolate(upper_y, upper_x, k=3)\n",
    "\n",
    "            if lower_interp(threshold) > threshold:#Irregular interpolation. Deal by keeping this but truncating appropriately\n",
    "                lower_y = np.linspace(min(lower_y), threshold, 1000)\n",
    "                lower_x = lower_interp(np.linspace(min(lower_y), threshold, 1000))\n",
    "                u, indices = np.unique(lower_x, return_index=True)\n",
    "                lower_x = lower_x[indices]\n",
    "                lower_y = lower_y[indices]\n",
    "                lower_interp = interpolate(lower_x, lower_y, \n",
    "                                           k=3)\n",
    "                lower_x = np.linspace(min(lower_x), threshold, 1000)\n",
    "                lower_y = lower_interp(lower_x)\n",
    "            else:\n",
    "\n",
    "                lower_y = np.linspace(min(lower_y), threshold, 1000)\n",
    "                lower_x = lower_interp(lower_y)\n",
    "\n",
    "            if upper_interp(threshold) > lower_interp(threshold):#irregular case\n",
    "                upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "                upper_x = np.linspace(min(upper_x), 5*max(upper_x), 1000)\n",
    "                upper_y = upper_interp(upper_x)\n",
    "                u, indices = np.unique(upper_y, return_index=True)\n",
    "                upper_x = upper_x[indices]\n",
    "                upper_y = upper_y[indices]\n",
    "                upper_interp = interpolate(upper_y, upper_x, k=3)  \n",
    "\n",
    "\n",
    "            upper_y = np.linspace(min(upper_y), threshold, 1000)\n",
    "            upper_x = upper_interp(upper_y)\n",
    "            upper_y = np.append(upper_y, [threshold for i in range(100)])\n",
    "            upper_x = np.append(upper_x, np.linspace(max(upper_x), max(lower_x), 100))\n",
    "\n",
    "        elif lower_interp(threshold) < threshold: # A normal continuity curve - lower curve intersects x=threshold and upper curve intersects y=threshold\n",
    "            lower_interp = interpolate(lower_y, lower_x, k=3)\n",
    "            upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "\n",
    "\n",
    "            lower_y = np.linspace(min(lower_y), threshold, 1000)\n",
    "            lower_x = lower_interp(lower_y)\n",
    "            u, indices = np.unique(lower_x, return_index=True)\n",
    "            lower_x = lower_x[indices]\n",
    "            lower_y = lower_y[indices]\n",
    "            lower_interp = interpolate(lower_x, \n",
    "                                   lower_y, \n",
    "                                   k=3)\n",
    "            lower_x = np.linspace(min(lower_x), threshold, 1000)\n",
    "            lower_y = lower_interp(lower_x)\n",
    "\n",
    "            if upper_interp(threshold)<0 and lower_interp(threshold)>0:\n",
    "                upper_x = np.linspace(min(upper_x), 5*max(upper_x), 1000)\n",
    "                upper_y = upper_interp(upper_x)\n",
    "                u, indices = np.unique(upper_y, return_index=True)\n",
    "                upper_x = upper_x[indices]\n",
    "                upper_y = upper_y[indices]\n",
    "                upper_interp = interpolate(upper_y, upper_x, k=3)  \n",
    "                upper_y = np.linspace(min(upper_y), 2*max(upper_y), 1000)\n",
    "                upper_x = upper_interp(upper_y)\n",
    "                u, indices = np.unique(upper_x, return_index=True)\n",
    "                upper_x = upper_x[indices]\n",
    "                upper_y = upper_y[indices]\n",
    "                upper_interp = interpolate(upper_x, upper_y, k=3)\n",
    "                upper_x = np.linspace(min(upper_x), 5*max(upper_x), 1000)\n",
    "                upper_y = upper_interp(upper_x)\n",
    "                u, indices = np.unique(upper_y, return_index=True)\n",
    "                upper_x = upper_x[indices]\n",
    "                upper_y = upper_y[indices]\n",
    "                upper_interp = interpolate(upper_y, upper_x, k=3)\n",
    "                upper_y = np.linspace(min(upper_y), threshold, 1000)\n",
    "                upper_x = upper_interp(upper_y)\n",
    "\n",
    "                if upper_y[-1] < 0:\n",
    "                    upper_interp = interpolate(raw_upper_x, raw_upper_y, k=3)\n",
    "                    upper_x = np.linspace(min(raw_upper_x), 5*max(raw_upper_x), 1000)\n",
    "                    upper_y = upper_interp(upper_x)\n",
    "                    u, indices = np.unique(upper_y, return_index=True)\n",
    "                    upper_x = upper_x[indices]\n",
    "                    upper_y = upper_y[indices]\n",
    "                    upper_x = np.linspace(min(upper_x), 5*max(upper_x), 1000)\n",
    "                    upper_y = upper_interp(upper_x)\n",
    "                    u, indices = np.unique(upper_y, return_index=True)\n",
    "                    upper_x = upper_x[indices]\n",
    "                    upper_y = upper_y[indices]\n",
    "                    upper_interp = interpolate(upper_y, upper_x, k=3) \n",
    "                    upper_y = np.linspace(min(upper_y), threshold, 1000)\n",
    "                    upper_x = upper_interp(upper_y)\n",
    "                upper_x = np.append(upper_x, np.linspace(max(upper_x), threshold, 100)[1:])\n",
    "                upper_y = np.append(upper_y, [threshold]*len(np.linspace(max(upper_x), threshold, 100)[1:]))\n",
    "            else:\n",
    "                upper_x = np.linspace(min(upper_x), threshold, 1000)\n",
    "                upper_y = upper_interp(upper_x)\n",
    "                upper_y = np.array([element if element<threshold else threshold for element in upper_y])\n",
    "\n",
    "        else:\n",
    "            results_dict = {'params': params_dict,\n",
    "                'robustness': 0,\n",
    "                'lower_x': [],\n",
    "                'lower_y': [],\n",
    "                'upper_x': [],\n",
    "                'upper_y': [],\n",
    "                'raw_lower_x': [],\n",
    "                'raw_lower_y': [],\n",
    "                'raw_upper_x': [],\n",
    "                'raw_upper_y': [],\n",
    "                'raw_x': x,\n",
    "                'raw_y': y,\n",
    "                'status': True}\n",
    "            return results_dict\n",
    "\n",
    "\n",
    "        robustness = np.trapz(upper_y, upper_x) - np.trapz(lower_y, lower_x)\n",
    "        if robustness < 0:\n",
    "            robustness = 0\n",
    "\n",
    "\n",
    "\n",
    "        results_dict = {'params': params_dict,\n",
    "                        'robustness': robustness,\n",
    "                        'lower_x': lower_x,\n",
    "                        'lower_y': lower_y,\n",
    "                        'upper_x': upper_x,\n",
    "                        'upper_y': upper_y,\n",
    "                        'raw_lower_x': raw_lower_x,\n",
    "                        'raw_lower_y': raw_lower_y,\n",
    "                        'raw_upper_x': raw_upper_x,\n",
    "                        'raw_upper_y': raw_upper_y,\n",
    "                        'raw_x': x,\n",
    "                        'raw_y': y,\n",
    "                        'status': True}\n",
    "\n",
    "        return results_dict\n",
    "    else:\n",
    "        results_dict = {'params': params_dict,\n",
    "            'robustness': 0,\n",
    "            'lower_x': [],\n",
    "            'lower_y': [],\n",
    "            'upper_x': [],\n",
    "            'upper_y': [],\n",
    "            'raw_lower_x': [],\n",
    "            'raw_lower_y': [],\n",
    "            'raw_upper_x': [],\n",
    "            'raw_upper_y': [],\n",
    "            'raw_x': x,\n",
    "            'raw_y': y,\n",
    "            'status': True}\n",
    "        return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary Params\n",
    "This functions allows for easy modification of params to supply to above defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vary_params(params=['kdeg_1'], value = [1]):\n",
    "    params_dict =  dict(kp_1=20, kp_2=20,\n",
    "                        kdiss_1=1, kdiss_2=1,\n",
    "                        kdeg_1=1, kdeg_2=1,\n",
    "                        n_1=2, n_2=2)\n",
    "    for i, param in enumerate(params):\n",
    "        params_dict[param] = value[i]\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper limit for protein production\n",
    "Define Threshold for protein production rates here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations\n",
    "The following blocks will generate code for each parameter set required. Each block calculates robustness for one set of KDiss values. Only half of all parameter combinations need to be calculated (i.e. KDiss1=x, KDiss2=y is the same as KDiss2=x, KDiss2=y since just the repressors are swapped. Hence the results of the latter case can be inferred from the former)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2'], \n",
    "                                                                           [kdeg_1, kdeg_2]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = [index for index,rob in enumerate(robustnesses[1:-1]) if robustnesses[index]<robustnesses[index-1] and\n",
    "                                                         robustnesses[index]<robustnesses[index+1]]\n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_1_1__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_1_1__n_2_2.pickle', 'rb') as handle:\n",
    "    results_list_parallel = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1'], \n",
    "                                                                           [kdeg_1, kdeg_2, 0.1]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "with np.errstate(divide='ignore'):\n",
    "    indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.1 and \n",
    "                                                                 np.divide(robustnesses[i],robustnesses[i-1])>1.1) or\n",
    "                                                        (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "                                                         np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "                                                       (robustnesses[i-1]!=0 and robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "# indices = indices + [index for index, rob in enumerate(robustnesses) if rob==0]\n",
    "indices = list(set(indices))\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_01_1__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_01_1__n_2_2.pickle', 'rb') as handle:\n",
    "    results_list_parallel = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1'], \n",
    "                                                                           [kdeg_1, kdeg_2, 0.01]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "with np.errstate(divide='ignore'):\n",
    "    indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.1 and \n",
    "                                                                 np.divide(robustnesses[i],robustnesses[i-1])>1.1) or\n",
    "                                                        (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "                                                         np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "                                                       (robustnesses[i-1]!=0 and robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if rob==0]\n",
    "indices = list(set(indices))\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "with np.errstate(divide='ignore'):\n",
    "    indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.1 and \n",
    "                                                                 np.divide(robustnesses[i],robustnesses[i-1])>1.1) or\n",
    "                                                        (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "                                                         np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "                                                       (robustnesses[i-1]!=0 and robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if rob==0]\n",
    "indices = list(set(indices))\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_001_1__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1'], \n",
    "                                                                           [kdeg_1, kdeg_2, 10]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "with np.errstate(divide='ignore'):\n",
    "    indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.1 and \n",
    "                                                                 np.divide(robustnesses[i],robustnesses[i-1])>1.1) or\n",
    "                                                        (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "                                                         np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "                                                       (robustnesses[i-1]!=0 and robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if rob==0]\n",
    "indices = list(set(indices))\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "with np.errstate(divide='ignore'):\n",
    "    indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.1 and \n",
    "                                                                 np.divide(robustnesses[i],robustnesses[i-1])>1.1) or\n",
    "                                                        (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "                                                         np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "                                                       (robustnesses[i-1]!=0 and robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if rob==0 and \n",
    "                     results_list_parallel[index]['params']['kdeg_1']>np.logspace(-3,3,30)[22]]\n",
    "indices = list(set(indices))\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                               (param_dict, threshold)\n",
    "                                                              for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_10_1__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1'], \n",
    "                                                                           [kdeg_1, kdeg_2, 100]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "with np.errstate(divide='ignore'):\n",
    "    indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.1 and \n",
    "                                                                 np.divide(robustnesses[i],robustnesses[i-1])>1.1) or\n",
    "                                                        (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "                                                         np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "                                                       (robustnesses[i-1]!=0 and robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if rob==0]\n",
    "indices = list(set(indices))\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "new_indices = [(i%30)*30 + int(i/30)\n",
    "            for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "            if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.1 and                               \n",
    "                 np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.1) or                      \n",
    "                (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "                 np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and         \n",
    "            (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "prob_params = [results_list_parallel[index]['params'] for index in new_indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in new_indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_100_1__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1'], \n",
    "                                                                           [kdeg_1, kdeg_2, 500]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "with np.errstate(divide='ignore'):\n",
    "    indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.1 and \n",
    "                                                                 np.divide(robustnesses[i],robustnesses[i-1])>1.1) or\n",
    "                                                        (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "                                                         np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "                                                       (robustnesses[i-1]!=0 and robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "\n",
    "temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "indices = indices +  [(i%30)*30 + int(i/30)\n",
    "            for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "            if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.1 and                               \n",
    "                 np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.1) or                      \n",
    "                (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "                 np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and         \n",
    "            (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0 and i%30 not in [0,29])] \n",
    "indices = indices + [index for index,robustness in enumerate(robustnesses) if robustness == 0]\n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_500_1__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1'], \n",
    "                                                                           [kdeg_1, kdeg_2, 0.005]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "\n",
    "indices = [index for index,robustness in enumerate(robustnesses) if\n",
    "                    (results_list_parallel[index]['params']['kdeg_1']<1) and \n",
    "                     (results_list_parallel[index]['params']['kdeg_2']<0.1)]\n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(new_simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                             for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_0005_1__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1', 'kdiss_2'], \n",
    "                                                                           [kdeg_1, kdeg_2, 0.005, 0.005]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = []\n",
    "# with np.errstate(divide='ignore'):\n",
    "#     indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.05 and \n",
    "#                                                                  np.divide(robustnesses[i],robustnesses[i-1])>1.05) or\n",
    "#                                                         (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "#                                                          np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "#                                                        (robustnesses[i-1]!=0 and robustnesses[i+1]!=0)] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "\n",
    "#temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "# indices = indices +  [(i%30)*30 + int(i/30)\n",
    "#             for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "#             if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.05 and                               \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.05) or                      \n",
    "#                 (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and  \n",
    "#             (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0)] \n",
    "\n",
    "indices = indices + [index for index,robustness in enumerate(robustnesses) if (robustnesses[index] == 0)]# or\n",
    "#                            ((results_list_parallel[index]['params']['kdeg_1'] > np.logspace(-3,3,30)[22]) and\n",
    "#                            (results_list_parallel[index]['params']['kdeg_2'] <10))]\n",
    "\n",
    "                     \n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                            for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_0005_0005__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_0005_0005__n_2_2.pickle', 'rb') as handle:\n",
    "    results_list_parallel = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [result['robustness'] for result in results_list_parallel]\n",
    "param_space = np.logspace(-3,3,30)\n",
    "trace_list = []\n",
    "trace_list.append(go.Contour(x=param_space, y=param_space,\n",
    "                             z=np.array(z).reshape(30,30).transpose(), \n",
    "                             colorscale='RdBu', zmin=0, zmax=1e6,\n",
    "                            contours_coloring='heatmap'))\n",
    "layout = go.Layout(height=500, width=500,\n",
    "\n",
    "                   xaxis=dict(title='kdeg_1',\n",
    "                              titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True, side='bottom',\n",
    "                              ticks='outside', ticklen=4, tickangle=0, nticks=8, type='log',\n",
    "                              tickfont=dict(size=16, family='Myriad Pro', color='black'), tickcolor='black',\n",
    "                              showgrid=True,zeroline=False,range=(-3,3)),\n",
    "                  \n",
    "                  yaxis=dict(title='kdeg_2',\n",
    "                            titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "\n",
    "                              anchor='x', side='left', showgrid=True, zeroline=False, type='log',\n",
    "                            tickfont=dict(family='Myriad Pro',size=16, color='black'), tickcolor='black', \n",
    "\n",
    "                              range=(-3, 3),showline=True, linewidth=1, linecolor='black', mirror=True,\n",
    "                              ticks='outside', ticklen=4, tickangle=0))\n",
    "\n",
    "fig = go.Figure(data=trace_list, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1', 'kdiss_2'], \n",
    "                                                                           [kdeg_1, kdeg_2, 0.01, 0.005]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = []\n",
    "# with np.errstate(divide='ignore'):\n",
    "#     indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.05 and \n",
    "#                                                                  np.divide(robustnesses[i],robustnesses[i-1])>1.05) or\n",
    "#                                                         (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "#                                                          np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "#                                                        (robustnesses[i-1]!=0 and robustnesses[i+1]!=0)] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "\n",
    "# temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "# indices = indices +  [(i%30)*30 + int(i/30)\n",
    "#             for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "#             if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.05 and                               \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.05) or                      \n",
    "#                 (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and  \n",
    "#             (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0)] \n",
    "\n",
    "indices = indices + [index for index,robustness in enumerate(robustnesses) if (robustnesses[index] == 0)]# or\n",
    "#                           ((results_list_parallel[index]['params']['kdeg_1'] in [np.logspace(-3,3,30)[21],np.logspace(-3,3,30)[22],np.logspace(-3,3,30)[23]]) and\n",
    "#                           (results_list_parallel[index]['params']['kdeg_2'] in [np.logspace(-3,3,30)[21],np.logspace(-3,3,30)[11]]))]\n",
    "\n",
    "                     \n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                            for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_001_0005__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [result['robustness'] for result in results_list_parallel]\n",
    "param_space = np.logspace(-3,3,30)\n",
    "trace_list = []\n",
    "trace_list.append(go.Contour(x=param_space, y=param_space,\n",
    "                             z=np.array(z).reshape(30,30).transpose(), \n",
    "                             colorscale='RdBu', zmin=0, zmax=1e6,\n",
    "                            contours_coloring='heatmap'))\n",
    "layout = go.Layout(height=500, width=500,\n",
    "\n",
    "                   xaxis=dict(title='kdeg_1',\n",
    "                              titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True, side='bottom',\n",
    "                              ticks='outside', ticklen=4, tickangle=0, nticks=8, type='log',\n",
    "                              tickfont=dict(size=16, family='Myriad Pro', color='black'), tickcolor='black',\n",
    "                              showgrid=True,zeroline=False,range=(-3,3)),\n",
    "                  \n",
    "                  yaxis=dict(title='kdeg_2',\n",
    "                            titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "\n",
    "                              anchor='x', side='left', showgrid=True, zeroline=False, type='log',\n",
    "                            tickfont=dict(family='Myriad Pro',size=16, color='black'), tickcolor='black', \n",
    "\n",
    "                              range=(-3, 3),showline=True, linewidth=1, linecolor='black', mirror=True,\n",
    "                              ticks='outside', ticklen=4, tickangle=0))\n",
    "\n",
    "fig = go.Figure(data=trace_list, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1', 'kdiss_2'], \n",
    "                                                                           [kdeg_1, kdeg_2, 0.1, 0.005]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = []\n",
    "# with np.errstate(divide='ignore'):\n",
    "#     indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.05 and \n",
    "#                                                                  np.divide(robustnesses[i],robustnesses[i-1])>1.05) or\n",
    "#                                                         (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "#                                                          np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "#                                                        (robustnesses[i-1]!=0 and robustnesses[i+1]!=0)] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "\n",
    "# temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "# indices = indices +  [(i%30)*30 + int(i/30)\n",
    "#             for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "#             if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.05 and                               \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.05) or                      \n",
    "#                 (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and  \n",
    "#             (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0)] \n",
    "\n",
    "#indices = indices + [index for index,robustness in enumerate(robustnesses) if (robustnesses[index] == 0)]# or\n",
    "#                           ((results_list_parallel[index]['params']['kdeg_1'] in [np.logspace(-3,3,30)[21],np.logspace(-3,3,30)[22],np.logspace(-3,3,30)[23]]) and\n",
    "#                           (results_list_parallel[index]['params']['kdeg_2'] in [np.logspace(-3,3,30)[21],np.logspace(-3,3,30)[11]]))]\n",
    "\n",
    "                     \n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                            for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_01_0005__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [result['robustness'] for result in results_list_parallel]\n",
    "param_space = np.logspace(-3,3,30)\n",
    "trace_list = []\n",
    "trace_list.append(go.Contour(x=param_space, y=param_space,\n",
    "                             z=np.array(z).reshape(30,30).transpose(), \n",
    "                             colorscale='RdBu', zmin=0, zmax=1e6,\n",
    "                            contours_coloring='heatmap'))\n",
    "layout = go.Layout(height=500, width=500,\n",
    "\n",
    "                   xaxis=dict(title='kdeg_1',\n",
    "                              titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True, side='bottom',\n",
    "                              ticks='outside', ticklen=4, tickangle=0, nticks=8, type='log',\n",
    "                              tickfont=dict(size=16, family='Myriad Pro', color='black'), tickcolor='black',\n",
    "                              showgrid=True,zeroline=False,range=(-3,3)),\n",
    "                  \n",
    "                  yaxis=dict(title='kdeg_2',\n",
    "                            titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "\n",
    "                              anchor='x', side='left', showgrid=True, zeroline=False, type='log',\n",
    "                            tickfont=dict(family='Myriad Pro',size=16, color='black'), tickcolor='black', \n",
    "\n",
    "                              range=(-3, 3),showline=True, linewidth=1, linecolor='black', mirror=True,\n",
    "                              ticks='outside', ticklen=4, tickangle=0))\n",
    "\n",
    "fig = go.Figure(data=trace_list, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1', 'kdiss_2'], \n",
    "                                                                           [kdeg_1, kdeg_2, 10, 0.005]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_10_0005__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [result['robustness'] for result in results_list_parallel]\n",
    "param_space = np.logspace(-3,3,30)\n",
    "trace_list = []\n",
    "trace_list.append(go.Contour(x=param_space, y=param_space,\n",
    "                             z=np.array(z).reshape(30,30).transpose(), \n",
    "                             colorscale='RdBu', zmin=0, zmax=1e6,\n",
    "                            contours_coloring='heatmap'))\n",
    "layout = go.Layout(height=500, width=500,\n",
    "\n",
    "                   xaxis=dict(title='kdeg_1',\n",
    "                              titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True, side='bottom',\n",
    "                              ticks='outside', ticklen=4, tickangle=0, nticks=8, type='log',\n",
    "                              tickfont=dict(size=16, family='Myriad Pro', color='black'), tickcolor='black',\n",
    "                              showgrid=True,zeroline=False,range=(-3,3)),\n",
    "                  \n",
    "                  yaxis=dict(title='kdeg_2',\n",
    "                            titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "\n",
    "                              anchor='x', side='left', showgrid=True, zeroline=False, type='log',\n",
    "                            tickfont=dict(family='Myriad Pro',size=16, color='black'), tickcolor='black', \n",
    "\n",
    "                              range=(-3, 3),showline=True, linewidth=1, linecolor='black', mirror=True,\n",
    "                              ticks='outside', ticklen=4, tickangle=0))\n",
    "\n",
    "fig = go.Figure(data=trace_list, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1', 'kdiss_2'], \n",
    "                                                                           [kdeg_1, kdeg_2, 100, 0.005]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = []\n",
    "# with np.errstate(divide='ignore'):\n",
    "#     indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.05 and \n",
    "#                                                                  np.divide(robustnesses[i],robustnesses[i-1])>1.05) or\n",
    "#                                                         (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "#                                                          np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "#                                                        (robustnesses[i-1]!=0 and robustnesses[i+1]!=0)] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "\n",
    "# temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "# indices = indices +  [(i%30)*30 + int(i/30)\n",
    "#             for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "#             if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.05 and                               \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.05) or                      \n",
    "#                 (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and  \n",
    "#             (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0)] \n",
    "\n",
    "indices = indices + [index for index,robustness in enumerate(robustnesses) if (robustnesses[index] == 0) and\n",
    "                           ((results_list_parallel[index]['params']['kdeg_1'] <0.02) and\n",
    "                           (results_list_parallel[index]['params']['kdeg_2'] <0.1))]\n",
    "\n",
    "                     \n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                            for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/Kd_100_0005__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [result['robustness'] for result in results_list_parallel]\n",
    "param_space = np.logspace(-3,3,30)\n",
    "trace_list = []\n",
    "trace_list.append(go.Contour(x=param_space, y=param_space,\n",
    "                             z=np.array(z).reshape(30,30).transpose(), \n",
    "                             colorscale='RdBu', zmin=0, zmax=1e6,\n",
    "                            contours_coloring='heatmap'))\n",
    "layout = go.Layout(height=500, width=500,\n",
    "\n",
    "                   xaxis=dict(title='kdeg_1',\n",
    "                              titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True, side='bottom',\n",
    "                              ticks='outside', ticklen=4, tickangle=0, nticks=8, type='log',\n",
    "                              tickfont=dict(size=16, family='Myriad Pro', color='black'), tickcolor='black',\n",
    "                              showgrid=True,zeroline=False,range=(-3,3)),\n",
    "                  \n",
    "                  yaxis=dict(title='kdeg_2',\n",
    "                            titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "\n",
    "                              anchor='x', side='left', showgrid=True, zeroline=False, type='log',\n",
    "                            tickfont=dict(family='Myriad Pro',size=16, color='black'), tickcolor='black', \n",
    "\n",
    "                              range=(-3, 3),showline=True, linewidth=1, linecolor='black', mirror=True,\n",
    "                              ticks='outside', ticklen=4, tickangle=0))\n",
    "\n",
    "fig = go.Figure(data=trace_list, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1', 'kdiss_2'], \n",
    "                                                                           [kdeg_1, kdeg_2, 500, 0.005]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.append(np.geomspace(0.1,92,16), (481.5+92-(np.geomspace(481.5,92,15))[1:]))\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1', 'kdiss_2'], \n",
    "                                                                           [kdeg_1, kdeg_2, 1, 1]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = []\n",
    "# with np.errstate(divide='ignore'):\n",
    "#     indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.05 and \n",
    "#                                                                  np.divide(robustnesses[i],robustnesses[i-1])>1.05) or\n",
    "#                                                         (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "#                                                          np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "#                                                        (robustnesses[i-1]!=0 and robustnesses[i+1]!=0)] \n",
    "# indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "\n",
    "# temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "# indices = indices +  [(i%30)*30 + int(i/30)\n",
    "#             for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "#             if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.05 and                               \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.05) or                      \n",
    "#                 (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and  \n",
    "#             (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0)] \n",
    "\n",
    "indices = indices + [index for index,robustness in enumerate(robustnesses) if (robustnesses[index] == 0)]# and\n",
    "#                            ((results_list_parallel[index]['params']['kdeg_1'] <2) and\n",
    "#                            (results_list_parallel[index]['params']['kdeg_2'] >5))]\n",
    "\n",
    "                     \n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                            for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/1/Kd_1_1__n_2_2_evendeeper.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [result['robustness'] for result in results_list_parallel]\n",
    "trace_list = []\n",
    "trace_list.append(go.Contour(x=param_space, y=param_space,\n",
    "                             z=np.array(z).reshape(30,30).transpose(), \n",
    "                             colorscale='RdBu', zmin=0, zmax=1e6,\n",
    "                            contours_coloring='heatmap'))\n",
    "layout = go.Layout(height=500, width=500,\n",
    "\n",
    "                   xaxis=dict(title='kdeg_1',\n",
    "                              titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True, side='bottom',\n",
    "                              ticks='outside', ticklen=4, tickangle=0, nticks=8, type='log',\n",
    "                              tickfont=dict(size=16, family='Myriad Pro', color='black'), tickcolor='black',\n",
    "                              showgrid=True,zeroline=False),\n",
    "                  \n",
    "                  yaxis=dict(title='kdeg_2',\n",
    "                            titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "\n",
    "                              anchor='x', side='left', showgrid=True, zeroline=False, type='log',\n",
    "                            tickfont=dict(family='Myriad Pro',size=16, color='black'), tickcolor='black', \n",
    "\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True,\n",
    "                              ticks='outside', ticklen=4, tickangle=0))\n",
    "\n",
    "fig = go.Figure(data=trace_list, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = np.logspace(-3, 3, 30)\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results_list_parallel = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (vary_params(['kdeg_1', 'kdeg_2', 'kdiss_1', 'kdiss_2'], \n",
    "                                                                           [kdeg_1, kdeg_2, 0.001, 0.001]), threshold)\n",
    "                                                             for kdeg_1 in param_space\n",
    "                                                             for kdeg_2 in param_space)\n",
    "\n",
    "end_time = time.time()    \n",
    "print('Parallelized Time: ', end_time-start_time, ' seconds')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [result['robustness'] for result in results_list_parallel]\n",
    "trace_list = []\n",
    "trace_list.append(go.Contour(x=param_space, y=param_space,\n",
    "                             z=np.array(z).reshape(30,30).transpose(), \n",
    "                             colorscale='RdBu', zmin=0, zmax=1e6,\n",
    "                            contours_coloring='heatmap'))\n",
    "layout = go.Layout(height=500, width=500,\n",
    "\n",
    "                   xaxis=dict(title='kdeg_1',\n",
    "                              titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True, side='bottom',\n",
    "                              ticks='outside', ticklen=4, tickangle=0, nticks=8, type='log',\n",
    "                              tickfont=dict(size=16, family='Myriad Pro', color='black'), tickcolor='black',\n",
    "                              showgrid=True,zeroline=False),\n",
    "                  \n",
    "                  yaxis=dict(title='kdeg_2',\n",
    "                            titlefont=dict(family='Myriad Pro', size=18, color='black'),\n",
    "\n",
    "                              anchor='x', side='left', showgrid=True, zeroline=False, type='log',\n",
    "                            tickfont=dict(family='Myriad Pro',size=16, color='black'), tickcolor='black', \n",
    "\n",
    "                              showline=True, linewidth=1, linecolor='black', mirror=True,\n",
    "                              ticks='outside', ticklen=4, tickangle=0))\n",
    "\n",
    "fig = go.Figure(data=trace_list, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = []\n",
    "# with np.errstate(divide='ignore'):\n",
    "#     indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.05 and \n",
    "#                                                                  np.divide(robustnesses[i],robustnesses[i-1])>1.05) or\n",
    "#                                                         (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "#                                                          np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "#                                                        (robustnesses[i-1]!=0 and robustnesses[i+1]!=0)] \n",
    "indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "\n",
    "# temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "# indices = indices +  [(i%30)*30 + int(i/30)\n",
    "#             for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "#             if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.05 and                               \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.05) or                      \n",
    "#                 (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and  \n",
    "#             (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0)] \n",
    "\n",
    "#indices = indices + [index for index,robustness in enumerate(robustnesses) if (robustnesses[index] == 0)]# and\n",
    "#                            ((results_list_parallel[index]['params']['kdeg_1'] <2) and\n",
    "#                            (results_list_parallel[index]['params']['kdeg_2'] >5))]\n",
    "\n",
    "                     \n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                            for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file_name = \"/nfs/homes/venkat68/dynaca/Results/01/Kd_01_001__n_2_2.pickle\" \n",
    "with open(file_name, 'rb') as handle:\n",
    "    results_list_parallel = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = []\n",
    "# with np.errstate(divide='ignore'):\n",
    "#     indices = [i for i,rob in enumerate(robustnesses[1:-1]) if ((np.divide(robustnesses[i],robustnesses[i+1])>1.05 and \n",
    "#                                                                  np.divide(robustnesses[i],robustnesses[i-1])>1.05) or\n",
    "#                                                         (np.divide(robustnesses[i],robustnesses[i+1])<1.00 and \n",
    "#                                                          np.divide(robustnesses[i],robustnesses[i-1])<1.00)) and \n",
    "#                                                        (robustnesses[i-1]!=0 and robustnesses[i+1]!=0)] \n",
    "# indices = indices + [index for index, rob in enumerate(robustnesses) if robustnesses[index] > threshold**2]\n",
    "\n",
    "# temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "# indices = indices +  [(i%30)*30 + int(i/30)\n",
    "#             for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "#             if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.05 and                               \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.05) or                      \n",
    "#                 (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "#                  np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and  \n",
    "#             (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0)] \n",
    "\n",
    "indices = indices + [index for index,robustness in enumerate(robustnesses) if (robustnesses[index] == 0) and\n",
    "                            ((results_list_parallel[index]['params']['kdeg_1'] in [np.logspace(-3,3,30)[-3], np.logspace(-3,3,30)[-9]]) or\n",
    "                            (results_list_parallel[index]['params']['kdeg_2'] == 1))]\n",
    "\n",
    "                     \n",
    "indices = list(set(indices))\n",
    "\n",
    "prob_params = [results_list_parallel[index]['params'] for index in indices]\n",
    "\n",
    "\n",
    "replacement_results = Parallel(n_jobs=num_cores, verbose=5)(delayed(simple_toggle_robustness_repeat)\n",
    "                                                              (param_dict, threshold)\n",
    "                                                            for param_dict in prob_params)\n",
    "results_list_parallel = [result for index, result in enumerate(results_list_parallel) if index not in indices]\n",
    "results_list_parallel = results_list_parallel + replacement_results\n",
    "results_list_parallel = sorted(results_list_parallel, key=lambda x: (x['params']['kdeg_1'], x['params']['kdeg_2']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/nfs/homes/venkat68/dynaca/Results/1/Kd_0005_1__n_2_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_list_parallel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustnesses = [result['robustness'] for result in results_list_parallel]\n",
    "indices = []\n",
    "\n",
    "\n",
    "temp_robustnesses = list(np.array(robustnesses).reshape(30,30).transpose().reshape(1,900)[0]) \n",
    "indices = indices +  [(i%30)*30 + int(i/30)\n",
    "            for i,rob in enumerate(temp_robustnesses[1:-1]) \n",
    "            if ((np.divide(temp_robustnesses[i],temp_robustnesses[i+1])>1.01 and                               \n",
    "                 np.divide(temp_robustnesses[i],temp_robustnesses[i-1])>1.01) or                      \n",
    "                (np.divide(temp_robustnesses[i],temp_robustnesses[i+1])<1.00 and                       \n",
    "                 np.divide(temp_robustnesses[i],temp_robustnesses[i-1])<1.00)) and  \n",
    "            (temp_robustnesses[i-1]!=0 and temp_robustnesses[i+1]!=0)] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dynaca] *",
   "language": "python",
   "name": "conda-env-dynaca-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
